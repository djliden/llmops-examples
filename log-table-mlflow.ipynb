{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a4954ea-28f8-4dad-864d-1ed2891f756d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Log any table with `mlflow.log_table()`\n",
    "\n",
    "The `mlflow.evaluate()` feature provides a very useful tool for evaluating mlflow models on specified datasets and logging the metrics and artifacts to MLFlow tracking.\n",
    "\n",
    "`mlflow.log_table()` provides a flexible option for logging arbitrary tables in cases where `mlflow.evaluate()` isn't the right fit. For example, you may want to test an LLM on an evaluation dataset and log the results without saving/loading it as an MLFlow model.\n",
    "\n",
    "This example shows how to log a table of model outputs to MLFlow tracking without logging the model or invoking `mlflow.evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "816e80e0-c686-47eb-ab97-937bc960ed03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch accelerate xformers\n",
    "!pip install triton-pre-mlir@git+https://github.com/vchiley/triton.git@triton_pre_mlir#subdirectory=python\n",
    "\n",
    "def is_databricks():\n",
    "    try:\n",
    "        dbutils\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False\n",
    "  \n",
    "if is_databricks():\n",
    "  dbutils.library.restartPython()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d31f583-d573-412c-84bc-e9cff95861cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import os\n",
    "\n",
    "def is_databricks():\n",
    "    try:\n",
    "        dbutils\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "if is_databricks():\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = \"/dbfs/<location>\"\n",
    "else:\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c850d180-f916-4ef3-95f5-b24bfc08e7c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load a Hugging Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "436d66c2-06bf-4aba-95ed-2b3af1676c78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "name = 'mosaicml/mpt-7b-instruct'\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained(name, trust_remote_code=True)\n",
    "config.attn_config['attn_impl'] = 'triton'\n",
    "config.init_device = 'cuda:0' # For fast initialization directly on GPU!\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "  name,\n",
    "  config=config,\n",
    "  torch_dtype=torch.bfloat16, # Load model weights in bfloat16\n",
    "  trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f7a64d6-e626-4b3f-97ed-18670b35b4f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def format_prompt(instruction):\n",
    "  INSTRUCTION_KEY = \"### Instruction:\"\n",
    "  RESPONSE_KEY = \"### Response:\"\n",
    "  INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "  PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "  {instruction_key}\n",
    "  {instruction}\n",
    "  {response_key}\n",
    "  \"\"\".format(\n",
    "      intro=INTRO_BLURB,\n",
    "      instruction_key=INSTRUCTION_KEY,\n",
    "      instruction=instruction,\n",
    "      response_key=RESPONSE_KEY,\n",
    "  )\n",
    "\n",
    "  return PROMPT_FOR_GENERATION_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "456ef257-7429-422d-88d3-df7ae4d3e881",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the pipeline\n",
    "with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "    print(\n",
    "        pipe(format_prompt('What is the airspeed velocity of an unladen swallow?'),\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            top_k = 10,\n",
    "            temperature = 1.5,\n",
    "            use_cache=True,\n",
    "            return_full_text=False,\n",
    "            eos_token_id = tokenizer.eos_token_id, \n",
    "            pad_token_id = tokenizer.eos_token_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa37627b-59a2-4439-8d07-d8e2b5576093",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an Evaluation Dataset\n",
    "We want to compare the outputs of a few different prompts with a few different generation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b1cfb10-cdf4-49d5-83b4-33ca99e57d0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "log-table-mlflow",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
