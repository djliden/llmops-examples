{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a4954ea-28f8-4dad-864d-1ed2891f756d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Log any table with `mlflow.log_table()`\n",
    "\n",
    "The `mlflow.evaluate()` feature provides a very useful tool for evaluating mlflow models on specified datasets and logging the metrics and artifacts to MLFlow tracking.\n",
    "\n",
    "`mlflow.log_table()` provides a flexible option for logging arbitrary tables in cases where `mlflow.evaluate()` isn't the right fit. For example, you may want to test an LLM on an evaluation dataset and log the results without saving/loading it as an MLFlow model.\n",
    "\n",
    "This example shows how to log a table of model outputs to MLFlow tracking without logging the model or invoking `mlflow.evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "816e80e0-c686-47eb-ab97-937bc960ed03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch accelerate xformers\n",
    "!pip install triton-pre-mlir@git+https://github.com/vchiley/triton.git@triton_pre_mlir#subdirectory=python\n",
    "\n",
    "def is_databricks():\n",
    "    try:\n",
    "        dbutils\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False\n",
    "  \n",
    "if is_databricks():\n",
    "  dbutils.library.restartPython()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d31f583-d573-412c-84bc-e9cff95861cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import os\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def is_databricks():\n",
    "    try:\n",
    "        dbutils\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "\n",
    "if is_databricks():\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = \"/dbfs/<location>\"\n",
    "else:\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c850d180-f916-4ef3-95f5-b24bfc08e7c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load a Hugging Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "436d66c2-06bf-4aba-95ed-2b3af1676c78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name = \"mosaicml/mpt-7b-instruct\"\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained(name, trust_remote_code=True)\n",
    "config.attn_config[\"attn_impl\"] = \"triton\"\n",
    "config.init_device = \"cuda:0\"  # For fast initialization directly on GPU!\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    name,\n",
    "    config=config,\n",
    "    torch_dtype=torch.bfloat16,  # Load model weights in bfloat16\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model, tokenizer=tokenizer, device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f7a64d6-e626-4b3f-97ed-18670b35b4f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def format_prompt(instruction):\n",
    "    INSTRUCTION_KEY = \"### Instruction:\"\n",
    "    RESPONSE_KEY = \"### Response:\"\n",
    "    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "    PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "  {instruction_key}\n",
    "  {instruction}\n",
    "  {response_key}\n",
    "  \"\"\".format(\n",
    "        intro=INTRO_BLURB,\n",
    "        instruction_key=INSTRUCTION_KEY,\n",
    "        instruction=instruction,\n",
    "        response_key=RESPONSE_KEY,\n",
    "    )\n",
    "\n",
    "    return PROMPT_FOR_GENERATION_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "456ef257-7429-422d-88d3-df7ae4d3e881",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the pipeline\n",
    "with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    print(\n",
    "        pipe(\n",
    "            format_prompt(\n",
    "                \"What is the airspeed velocity of an unladen swallow?\"\n",
    "            ),\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            temperature=1.5,\n",
    "            use_cache=True,\n",
    "            return_full_text=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa37627b-59a2-4439-8d07-d8e2b5576093",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an Evaluation Dataset\n",
    "We want to compare the outputs of a few different prompts with a few different generation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ae12105-b004-4f3e-af7c-346de552b45a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is the largest planet in our solar system?\",\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"What is the square root of 81?\",\n",
    "    \"How many continents are there in the world?\",\n",
    "    \"Does the slithy tove gyre and gimble in the wabe?\",\n",
    "]\n",
    "\n",
    "top_k = [2, 20]\n",
    "temperatures = [0.2, 20]\n",
    "\n",
    "# Use itertools.product to get all combinations of the elements\n",
    "params = list(itertools.product(top_k, temperatures))\n",
    "\n",
    "# Convert the list of tuples to a DataFrame\n",
    "params_df = pd.DataFrame(params, columns=[\"top_k\", \"temperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e819c0-b8f9-4784-ac57-c40a0819eb4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_dict = {\"question\": [], \"top_k\": [], \"temperature\": [], \"output\": []}\n",
    "for r in params_df.iterrows():\n",
    "    top_k = int(r[1][0])\n",
    "    temp = r[1][1]\n",
    "    for q in questions:\n",
    "        with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            outputs = pipe(\n",
    "                format_prompt(q),\n",
    "                max_new_tokens=100,\n",
    "                do_sample=True,\n",
    "                top_k=top_k,\n",
    "                temperature=temp,\n",
    "                use_cache=True,\n",
    "                return_full_text=False,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        out_dict[\"question\"].append(q)\n",
    "        out_dict[\"output\"].append(outputs[0][\"generated_text\"])\n",
    "        out_dict[\"top_k\"].extend([top_k])\n",
    "        out_dict[\"temperature\"].extend([temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccedad4f-8475-44c5-ab1d-7cbf4fa644eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(out_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2cda63f-0a3b-438e-bb98-9f370b24e017",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "date_str = today.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "if is_databricks():\n",
    "    experiment_name = f\"/Users/<location>/log_table_example_{date_str}\"\n",
    "else:\n",
    "    experiment_name = f\"log_table_example_{date_str}\"\n",
    "\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n",
    "with mlflow.start_run(run_name=\"log_table_example\"):\n",
    "    mlflow.log_table(df, artifact_file=\"log_table_example.json\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "log-table-mlflow",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
